{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPk2W7TzEfjfBgg1xIk0lHD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"r46Xp8dvbb53","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720171553693,"user_tz":-330,"elapsed":22143,"user":{"displayName":"Hariharan Ganapathy","userId":"18052769655460982476"}},"outputId":"4ac72357-f69b-4a77-f33e-bcbc31c577a9"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["'''\n","  Clones github repository to GDrive - Run it just once\n","'''\n","%%bash\n","cd /content/drive/MyDrive/Learn/guvi/labs/Assignments/PhonePePulse\n","mkdir -p phonepe\n","cd phonepe\n","git clone https://github.com/PhonePe/pulse.git\n"],"metadata":{"id":"2lsaeCnMbWf5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","  Data loading functions that are used to load data\n","  from the JSON files on disk and store them into\n","  corresponding data frames. The data frame is closely\n","  modeled after the database schema\n","'''\n","import pandas as pd\n","import json\n","import os\n","\n","def get_abs_fpaths(dir):\n","    for dirpath,_,filenames in os.walk(dir):\n","        for f in filenames:\n","            yield os.path.abspath(os.path.join(dirpath, f))\n","\n","# Load a JSON data file into a dataframe,given the full path\n","def load_file (f):\n","  try:\n","    df = pd.read_json(f)\n","    df.drop(columns=['success','code'])\n","    return df\n","  except:\n","    raise Exception(f'''File not found: {f}''')\n","\n","# Decode common record attributes from a JSON file\n","def load_common(f, record_class, retd):\n","  #print('''decode_common() - Start ''')\n","  state=None\n","  year=None\n","  quarter=None\n","  if 'state' in f:\n","    state,year,quarter = os.path.normpath(f).split(os.sep)[-3:]\n","  else:\n","    year,quarter=os.path.normpath(f).split(os.sep)[-2:]\n","  quarter=quarter.split('.')[0]\n","  geo_type='Country'\n","  geo_name='india'\n","  if year is not None and quarter is not None:\n","    if state is not None:\n","      geo_type='State'\n","      geo_name=state\n","\n","  #print('''decode_common() - End ''')\n","  retd['year'].append(year)\n","  retd['quarter'].append(quarter)\n","  retd['geo_type'].append(geo_type)\n","  retd['geo_name'].append(geo_name)\n","  return\n","\n","def load_top_txns(f,record_class,retd):\n","  #print('load_top_txns() - Start')\n","  # Load JSON contents into a temp dataframe\n","  df=load_file(f)\n","\n","  # Seek to the contents of the 'transaction' data\n","  txn_states = df.loc['states','data']\n","  txn_districts = df.loc['districts','data']\n","  txn_pincodes = df.loc['pincodes','data']\n","\n","  if txn_states is not None:\n","    for txn in txn_states:\n","      load_common(f, record_class, retd)\n","      retd['category'].append(None)\n","      retd['geo_type'][-1]='State'\n","      retd['geo_name'][-1]=txn['entityName']\n","      retd['stat_type'].append(txn['metric'][\"type\"])\n","      retd['count'].append(txn['metric'][\"count\"])\n","      retd['amount'].append(txn['metric'][\"amount\"])\n","\n","  if txn_districts is not None:\n","    for txn in txn_districts:\n","      load_common(f, record_class, retd)\n","      retd['category'].append(None)\n","      retd['geo_type'][-1]='District'\n","      retd['geo_name'][-1]=txn['entityName']\n","      retd['stat_type'].append(txn['metric'][\"type\"])\n","      retd['count'].append(txn['metric'][\"count\"])\n","      retd['amount'].append(txn['metric'][\"amount\"])\n","\n","  if txn_pincodes is not None:\n","    for txn in txn_pincodes:\n","      load_common(f, record_class, retd)\n","      retd['category'].append(None)\n","      retd['geo_type'][-1]='Pincode'\n","      retd['geo_name'][-1]=txn['entityName']\n","      retd['stat_type'].append(txn['metric'][\"type\"])\n","      retd['count'].append(txn['metric'][\"count\"])\n","      retd['amount'].append(txn['metric'][\"amount\"])\n","\n","  return\n","\n","def load_hover_txns(f,record_class,retd):\n","  return None\n","\n","# Decode 'transaction' record\n","def load_agg_txns(f,report_type,retd):\n","  #print('decode_txn() - Start')\n","\n","  # Load JSON contents into a temp dataframe\n","  df=load_file(f)\n","\n","  # Seek to the contents of the 'transaction' data\n","  txn_recs = df.loc['transactionData','data']\n","  for txn_rec in txn_recs:\n","    # Collect the common fields from path name\n","    load_common(f, report_type, retd)\n","\n","    # Process record for all category\n","    for payment_rec in txn_rec['paymentInstruments']:\n","      retd['category'].append(txn_rec[\"name\"])\n","      retd['stat_type'].append(payment_rec[\"type\"])\n","      retd['count'].append(payment_rec[\"count\"])\n","      retd['amount'].append(payment_rec[\"amount\"])\n","\n","  #print('decode_txn() - End')\n","  return\n","\n","def load_top_users(self,f,retd):\n","  # Load JSON contents into a temp dataframe\n","  df=Base.load_file(f)\n","\n","  # Seek to the contents of the 'transaction' data\n","  user_states = df.loc['states','data']\n","  user_districts = df.loc['districts','data']\n","  user_pincodes = df.loc['pincodes','data']\n","\n","\n","  if user_states is not None:\n","    for user in user_states:\n","      load_common(f,retd)\n","      retd['geo_type'][-1]='State'\n","      retd['geo_name'][-1]=user['name']\n","      retd['reg_users'].append(user['registeredUsers'])\n","\n","    if user_districts is not None:\n","      for user in user_districts:\n","        load_common(f,retd)\n","        retd['geo_type'][-1]='District'\n","        retd['geo_name'][-1]=user['name']\n","        retd['reg_users'].append(user['registeredUsers'])\n","\n","    if user_pincodes is not None:\n","      for user in user_pincodes:\n","        load_common(f,retd)\n","        retd['geo_type'][-1]='Pincode'\n","        retd['geo_name'][-1]=user['name']\n","        retd['reg_users'].append(user['registeredUsers'])\n","\n","def load_hover_users(f,record_class,retd):\n","  return None\n","\n","# Decode 'user' record\n","def load_agg_users(f,record_class,retd):\n","  #print('decode_user - Start')\n","\n","  # Load JSON contents into a temp dataframe\n","  df=load_file(f)\n","\n","  # Seek to the contents of the 'user.aggregated' data\n","  user_stat_rec = df.loc['aggregated','data']\n","\n","  #3print(f)\n","  #print (df.to_markdown())\n","  # Seek to the contents of the 'user.device' data\n","  device_recs = df.loc['usersByDevice','data']\n","\n","  # For each device row populate both aggregate and device fields\n","  if device_recs is not None:\n","    for device_rec in device_recs:\n","      # Collect the common fields from path name\n","      load_common(f, record_class,retd)\n","      retd['category'].append(None)\n","      retd['reg_users'].append(user_stat_rec['registeredUsers'])\n","      retd['app_opens'].append(user_stat_rec['appOpens'])\n","      retd['brand'].append(device_rec['brand'])\n","      retd['count'].append(device_rec['count'])\n","      retd['percentage'].append(device_rec['percentage'])\n","  else:\n","    load_common(f, record_class,retd)\n","    retd['category'].append(None)\n","    retd['reg_users'].append(user_stat_rec['registeredUsers'])\n","    retd['app_opens'].append(user_stat_rec['appOpens'])\n","    retd['brand'].append('Unknown')\n","    retd['count'].append(0)\n","    retd['percentage'].append(100)\n","\n","  #print('decode_user - End')\n","  return\n","\n","  def load_top_ins(self,f,retd):\n","    # Load JSON\n","    df=load_file(f)\n","\n","    # Seek to the contents of the 'transaction' data\n","    ins_states = df.loc['states','data']\n","    ins_districts = df.loc['districts','data']\n","    ins_pincodes = df.loc['pincodes','data']\n","\n","    if ins_states is not None:\n","      for ins in ins_states:\n","        load_common(f,retd)\n","        retd['geo_type'][-1]='State'\n","        retd['geo_name'][-1]=ins['entityName']\n","        retd['stat_type'].append(ins['metric'][\"type\"])\n","        retd['count'].append(ins['metric'][\"count\"])\n","        retd['amount'].append(ins['metric'][\"amount\"])\n","\n","    if ins_districts is not None:\n","      for ins in ins_districts:\n","        load_common(f,retd)\n","        retd['geo_type'][-1]='District'\n","        retd['geo_name'][-1]=ins['entityName']\n","        retd['stat_type'].append(ins['metric'][\"type\"])\n","        retd['count'].append(ins['metric'][\"count\"])\n","        retd['amount'].append(ins['metric'][\"amount\"])\n","\n","    if ins_pincodes is not None:\n","      for ins in ins_pincodes:\n","        load_common(f,retd)\n","        retd['geo_type'][-1]='Pincode'\n","        retd['geo_name'][-1]=ins['entityName']\n","        retd['stat_type'].append(ins['metric'][\"type\"])\n","        retd['count'].append(ins['metric'][\"count\"])\n","        retd['amount'].append(ins['metric'][\"amount\"])\n","\n","def load_hover_ins(f,record_class,retd):\n","  return None\n","\n","# Decode 'insurance' record\n","def load_agg_ins(f,record_class,retd):\n","  #print('decode_ins - Start')\n","\n","  # Load JSON contents into a temp dataframe\n","  df=load_file(f)\n","\n","  # print(df.to_markdown())\n","  # Seek to the contents of the 'insurance' data\n","  ins_recs = df.loc['transactionData','data']\n","\n","  # For each 'insurance' row populate fields\n","  for ins_rec in ins_recs:\n","    # Collect the common fields from path name\n","    load_common(f, record_class, retd)\n","    for payment_rec in ins_rec['paymentInstruments']:\n","      retd['category'].append(ins_rec[\"name\"])\n","      retd['stat_type'].append(payment_rec[\"type\"])\n","      retd['count'].append(payment_rec[\"count\"])\n","      retd['amount'].append(payment_rec[\"amount\"])\n","  #print('decode_ins - End')\n","  return\n","\n","# Suppoted record types\n","record_types = {\n","  \"transaction\":{\n","    \"columns\":['year','quarter', 'geo_type', 'geo_name', 'category', 'stat_type', 'count', 'amount'],\n","    \"loaders\":{\n","      \"aggregated\":load_agg_txns,\n","      #\"top\":load_top_txns,\n","      #\"hover\":load_hover_txns,\n","    }\n","  },\n","\n","  #\"user\":{\n","    #\"columns\":['year','quarter', 'geo_type', 'geo_name', 'category', 'reg_users', 'app_opens','brand','count','percentage'],\n","    #\"loaders\":{\n","       #\"aggregated\":load_agg_users,\n","  #       #\"top\":load_top_users,\n","  #       #\"hover\": load_hover_users\n","    #}\n","  #},\n","\n","  #\"insurance\":{\n","    #\"columns\":['year','quarter', 'geo_type', 'geo_name', 'category', 'stat_type', 'count', 'amount'],\n","    #\"loaders\":{\n","    #\"aggregated\":load_agg_ins,\n","  #       #\"top\":load_top_ins,\n","  #       #\"hover\":load_hover_ins\n","     #}\n","  #}\n","}\n","\n","# Supported record classes\n","report_type = {\n","    \"aggregated\":\"Aggregated\",\n","   # \"hover\": \"Hover\",\n","   # \"top\": \"Top\"\n","}\n","\n","def get_abs_fpaths(dir):\n","    for dirpath,_,filenames in os.walk(dir):\n","        for f in filenames:\n","            yield os.path.abspath(os.path.join(dirpath, f))\n","\n","# Load data\n","def load_data(root_dir):\n","\n","  print( '''load_data() - Start''')\n","  # Dictionary of resulting dataframes\n","  ret = dict()\n","\n","  # Get aggregate, top and map for each record type\n","  for rec_type in record_types.keys():\n","    ret[rec_type]=dict()\n","\n","    # Do this for every record class - aggregate, top and map/hover\n","    for report_type in record_types[rec_type]['loaders'].keys():\n","      # Set the columns of output dataframe\n","      columns=record_types[rec_type]['columns']\n","\n","      # Special treatment for rec_class='aggregate'\n","      if report_type =='aggregated':\n","        columns.append('category')\n","\n","      # Create an output dataframe to store record's from multiple files\n","      #ret_df = pd.DataFrame(columns)\n","      retd = dict()\n","      for c in columns:\n","        retd[c]=list()\n","\n","      # Add the output dataframe to the output dictionary of dataframes\n","      ret[rec_type][report_type]=retd\n","\n","      # Construct absolute path to folder containing files for\n","      # a record class and type\n","      full_path=f'''{root_dir}/{report_type}/{rec_type}'''\n","\n","      # Decode contents of each file accumulate in a dataframe\n","      count=0\n","      for f in get_abs_fpaths(full_path):\n","        loader = record_types[rec_type]['loaders'][report_type]\n","        loader(f,report_type,retd)\n","        count +=1\n","\n","  print( f'''load_data() {count} files processed - End''')\n","  return ret"],"metadata":{"id":"ZnaOijeiHD53","executionInfo":{"status":"ok","timestamp":1720171576318,"user_tz":-330,"elapsed":1118,"user":{"displayName":"Hariharan Ganapathy","userId":"18052769655460982476"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["'''\n","  Test program to load files from disk\n","'''\n","root_dir = \"/content/drive/MyDrive/Learn/guvi/labs/Assignments/PhonePePulse/phonepe/pulse/data\"\n","\n","#try:\n","ret = load_data(root_dir)\n","#print(pd.DataFrame(ret['transaction']['aggregated']).shape)\n","#print(pd.DataFrame(ret['user']['aggregated']).shape)\n","#print(pd.DataFrame(ret['insurance']['aggregated']).shape)\n","print(pd.DataFrame(ret['transaction']['top']).shape)\n","\n","\n","\n","#except Exception as e:\n","  #print(e)\n","\n"],"metadata":{"id":"Y0U-fDGybY09","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719491602196,"user_tz":-330,"elapsed":11962,"user":{"displayName":"Hariharan Ganapathy","userId":"18052769655460982476"}},"outputId":"09823398-cbc2-47a0-dd7a-d3c651fc921c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["load_data() - Start\n","load_data() 925 files processed - End\n","(17074, 8)\n"]}]}]}